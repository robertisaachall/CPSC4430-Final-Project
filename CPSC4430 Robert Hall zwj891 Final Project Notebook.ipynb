{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "appliances_dataframe = getDF(\"Pet_Supplies_5.json.gz')\n",
    "appliances_dataframe.to_pickle(\"pet_supplies_amazon_review_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to create reviews in a folder from source file. \n",
    "Function that when called and used the proper parameters will read in the .pkl file and create the .txt review inside the specified directory, and create it under the desired name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_review_in_folder(review_list,folder_name,file_name_cat):\n",
    "    number = 1\n",
    "    reviews = pd.read_pickle(review_list)\n",
    "    reviews = reviews['reviewText'].tolist()\n",
    "    reviews = list(set(reviews))\n",
    "    for review in reviews:\n",
    "        review_len = str(review).split()\n",
    "        if len(review_len) >= 30:\n",
    "            path = \"data/\" + folder_name\n",
    "            file_name = file_name_cat  + str(number) + \".txt\"      \n",
    "            number += 1\n",
    "            \n",
    "            document = re.sub(r'\\W', ' ', str(review))\n",
    "            document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "            document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "            document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "            document = re.sub(r'^b\\s+', '', document)\n",
    "            document = document.lower()\n",
    "            document = document.split()\n",
    "            document = ' '.join(document)\n",
    "\n",
    "            path = path + file_name\n",
    "            file = open(path,\"x\")\n",
    "            file.write(str(document))\n",
    "            file.close()         \n",
    "        else:      \n",
    "            continue      \n",
    "    return\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample useage of the create_review_in_folder function.\n",
    "Whenever you pass in the .pkl file, the directory, and the desired name for the review files it will read the pkl file and create in directory as requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_review_in_folder(\"video_game_amazon_review.pkl\",\"Video Games Amazon Reviews/\",\"video_games_amazon_review_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\Documents\\SCHOOL\\CPSC4430\\Final Project\\Text-Classification-of-Amazon-Review-Data\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I.\n",
    "Located cell below is used for simple logistic regression using a Count Vectorizer to embedd each word as an instance. We achieve a 0.9376 % accuracy for our model with no other modifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_data, y_train)\n",
    "score = classifier.score(X_test_data, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I. a\n",
    "Located below is the change from the default lbfgs optimizer to the newton-cg optimizer which gives us a marginal increase to 0.9382%, a change from the previous accuracy by 0.005%! Wow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "\n",
    "classifier = LogisticRegression(solver = \"newton-cg\") \n",
    "classifier.fit(X_train_data, y_train)\n",
    "score = classifier.score(X_test_data, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I. B\n",
    "Located section below is the code to produce multiple logistic regression models with different maximum iterations where the best performing model had the maximum iterations set at and had the accuracy of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 100 : 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 150 : 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 200 : 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 250 : 0.9386\n",
      "Accuracy for max_iter = 300 : 0.9384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "\n",
    "#Creating array of values to test for maximum iterations on logistic regression model. Iterations are increments of 50, the default is 100. \n",
    "maximum_iterations_array = [100,150,200,250,300]\n",
    "\n",
    "for iteration in maximum_iterations_array:\n",
    "    classifier = LogisticRegression(max_iter=iteration) \n",
    "    classifier.fit(X_train_data, y_train)\n",
    "    score = classifier.score(X_test_data, y_test)\n",
    "    print(\"Accuracy for max_iter = \" + str(iteration) + \" : \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I. C\n",
    "Located cell below is used for setting the maximum iteration of our logistic regression model to 250, and setting the optimizer function to use the Newton-CG method. Our reported accuracy from this model was: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "#Creating the logistic regression model at the calculated max iterations of 250 using the newton-cg optimizer.\n",
    "classifier = LogisticRegression(max_iter=250,solver = \"newton-cg\") \n",
    "classifier.fit(X_train_data, y_train)\n",
    "score = classifier.score(X_test_data, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I. D\n",
    "Located cell below is used for setting the multi_class hyerparameter to change the loss functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ovr Accuracy: 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ovr Accuracy: 0.9433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "#Creating the logistic regression model at the calculated max iterations of 250 using the newton-cg optimizer.\n",
    "classifier = LogisticRegression(max_iter=250) \n",
    "classifier.fit(X_train_data, y_train)\n",
    "score = classifier.score(X_test_data, y_test)\n",
    "print(\"Default Accuracy:\", score)\n",
    "\n",
    "ovr_classifier = LogisticRegression(max_iter=250,multi_class=\"ovr\") \n",
    "ovr_classifier.fit(X_train_data, y_train)\n",
    "ovr_score = ovr_classifier.score(X_test_data, y_test)\n",
    "print(\"Ovr Accuracy:\", ovr_score)\n",
    "\n",
    "multi_classifier = LogisticRegression(max_iter=250,multi_class=\"ovr\") \n",
    "multi_classifier.fit(X_train_data, y_train)\n",
    "multi_score = multi_classifier.score(X_test_data, y_test)\n",
    "print(\"Multi Accuracy:\", multi_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II.\n",
    "Located cell below is used for a simple Random Forest Classifier with the default N-estimators set at 100, with no random state. We achieve an accuracy of: 0.8951 for this base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "#Creating the random forest classifier with the default n_estimators to 100 and no random state. \n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "classifier.fit(X_train_data, y_train)\n",
    "\n",
    "forrest_prediction = classifier.predict(X_test_data)\n",
    "print(classification_report(y_test,forrest_prediction))\n",
    "print(accuracy_score(y_test, forrest_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II. a\n",
    "Located cell below is the change from the criterion for the classifer from the default of Gini-Index. The model reports an accuracy of 0.881. A minimal difference of 0.0151% for using Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1974\n",
      "           1       0.85      0.83      0.84      1945\n",
      "           2       0.90      0.86      0.88      2081\n",
      "           3       0.81      0.82      0.81      2029\n",
      "           4       0.94      0.95      0.94      1971\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "#Changed classifer hyper-parameter from the default Gini-Index to Entropy to determine the split. \n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0,criterion=\"entropy\")\n",
    "classifier.fit(X_train_data, y_train)\n",
    "\n",
    "forrest_prediction = classifier.predict(X_test_data)\n",
    "print(classification_report(y_test,forrest_prediction))\n",
    "print(accuracy_score(y_test, forrest_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II. B\n",
    "Located cell below is used to loop through an array of N-Estimators to print out and see the various accuracy for each N-Number of Trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for max_iter = 100 : 0.8961\n",
      "Accuracy for max_iter = 120 : 0.8982\n",
      "Accuracy for max_iter = 140 : 0.8983\n",
      "Accuracy for max_iter = 160 : 0.8989\n",
      "Accuracy for max_iter = 180 : 0.9029\n",
      "Accuracy for max_iter = 200 : 0.9018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "review_data = load_files(r\"data/\")\n",
    "X, y = review_data.data , review_data.target\n",
    "\n",
    "review_data_train, review_data_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review_data_train)\n",
    "\n",
    "\n",
    "X_train_data = vectorizer.transform(review_data_train)\n",
    "X_test_data = vectorizer.transform(review_data_test)\n",
    "\n",
    "n_estimators_array = [100,120,140,160,180,200]\n",
    "\n",
    "for n_estimator in n_estimators_array:\n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimator, random_state=0)\n",
    "    classifier.fit(X_train_data, y_train)\n",
    "    forrest_prediction = classifier.predict(X_test_data)\n",
    "    print(\"Accuracy for N-Trees = \" + str(n_estimator) + \" : \" + str(accuracy_score(y_test, forrest_prediction)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
